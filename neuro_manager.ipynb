{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOjPhR3v5O9kua+gchr6QS8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vadim-Kolesnikov/Neuro-manager/blob/main/neuro_manager.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Установка необходимых зависимостей"
      ],
      "metadata": {
        "id": "9jyqQ8VbEj9s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GRWKkWZxotj"
      },
      "outputs": [],
      "source": [
        "!pip install openai tiktoken langchain langchain-openai langchain-community chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Импорт библиотек"
      ],
      "metadata": {
        "id": "cF52uGplEzmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from openai import OpenAI\n",
        "import tiktoken\n",
        "import re\n",
        "import os\n",
        "import requests\n",
        "import getpass"
      ],
      "metadata": {
        "id": "h0_f7uzcnMri"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Общие переменные"
      ],
      "metadata": {
        "id": "6ej0zQFZE48v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Введите OpenAI API Key:\")\n",
        "MODEL_NAME = \"gpt-3.5-turbo\"\n",
        "MODEL = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "# ссылка на плохо структурированный документ\n",
        "DOC_URL = \"https://docs.google.com/document/d/1ami_prVapm4JeINas-LK_PI4KrALOwSZlDFhziLN5Cs/export?format=txt\""
      ],
      "metadata": {
        "id": "5xke6hwg0aYI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Структурирование текста"
      ],
      "metadata": {
        "id": "Ea-csavpFD7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_text = \"\"\n",
        "start_text = requests.get(DOC_URL).text\n",
        "\n",
        "# загружаем куски текста в модель и просим GPT их структурировать\n",
        "# после чего структурированный кусок добавляю к остальному тексту\n",
        "# и так пока текст не закончится\n",
        "while len(start_text) != 0:\n",
        "  query1 = f\"я отправлю тебе текст ты его структурируешь и отправишь обратно. вот текст: {start_text[:3000]}\"\n",
        "  messages = [\n",
        "                {\"role\": \"system\", \"content\": \"\"},\n",
        "                {\"role\": \"user\", \"content\": query1}\n",
        "            ]\n",
        "  completion = MODEL.chat.completions.create(\n",
        "               model=MODEL_NAME,\n",
        "               messages=messages,\n",
        "               temperature=1)\n",
        "\n",
        "  final_text += completion.choices[0].message.content\n",
        "\n",
        "  start_text = start_text[3000:]"
      ],
      "metadata": {
        "id": "JNymyX10vUkD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вспомогательный класс"
      ],
      "metadata": {
        "id": "TYp3_05WFSGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# служебная информация для модели\n",
        "models_info = [\n",
        "    {\n",
        "        \"model_name\": \"Нейро-менеджер поддержки начинающих преподавателей в онлайн школе\",\n",
        "        \"fit_doc\": final_text,\n",
        "        \"query_example\": \"Что делать если ученик не пришел на урок?\",\n",
        "        \"role\": '''Ты менеджер поддержки преподавателей в онлайн школе программирования под названием CompanyName,\n",
        "                   к тебе могут обращаться начинающие преподаватели за подсказками и ответами на их вопросы в чате компании.\n",
        "                   Постарайся дать развернутый ответ, твоя задача ответить так, чтобы у преподавателя не осталось больше вопросов к тебе.\n",
        "                   Отвечай по существу, без лишних эмоций и слов, от тебя нужна только точная информация.\n",
        "                   Отвечай максимально точно по документу, не придумывай ничего от себя.\n",
        "                   Документ с информацией для ответа преподавателю: '''\n",
        "    }\n",
        "]\n",
        "\n",
        "\n",
        "# класс для более комфортного взаимодействия с моделью\n",
        "class Employee:\n",
        "  def __init__(self):\n",
        "    self.model_name = MODEL_NAME\n",
        "    self.model = MODEL\n",
        "    self.search_base = None\n",
        "    self.log = []\n",
        "\n",
        "  # логирование\n",
        "  def add_log(self, log_text):\n",
        "    self.log.append(log_text)\n",
        "\n",
        "  # функция для создания векторной базы данных\n",
        "  def create_search_base(self, text):\n",
        "        # разбиваем текст на чанки\n",
        "        source_chunks = []\n",
        "        splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1024, chunk_overlap=0)\n",
        "\n",
        "        for chunk in splitter.split_text(text):\n",
        "            source_chunks.append(Document(page_content=chunk, metadata={}))\n",
        "\n",
        "        # формируем из чанков векторную базу данных используя эмбендинги OpenAi\n",
        "        self.search_base = Chroma.from_documents(source_chunks, OpenAIEmbeddings())\n",
        "        self.add_log('Данные из документа загружены в в векторную базу данных')\n",
        "\n",
        "        return self.search_base\n",
        "\n",
        "  # генераия ответа\n",
        "  def get_answer(self, system, topic, temp = 100):\n",
        "        temp = temp / 100\n",
        "        if not self.search_base:\n",
        "            self.add_log('Модель необходимо обучить!')\n",
        "            return ''\n",
        "\n",
        "        # ищем в базе максимально похожий на вопрос раздел\n",
        "        docs = self.search_base.similarity_search(topic, k=5)\n",
        "        message_content = re.sub(r'\\n{2}', ' ', '\\n '.join([f'Отрывок документа №{i+1}:\\n' + doc.page_content + '\\\\n' for i, doc in enumerate(docs)]))\n",
        "\n",
        "        # найденный раздел передаем модели в качестве опорного документа\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system + f\"{message_content}\"},\n",
        "            {\"role\": \"user\", \"content\": topic}\n",
        "        ]\n",
        "\n",
        "        # формируем запрос\n",
        "        completion = self.model.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=messages,\n",
        "            temperature=temp\n",
        "        )\n",
        "\n",
        "        # логи\n",
        "        self.add_log(f'Токенов использовано всего (вопрос): {completion.usage.prompt_tokens}')\n",
        "        self.add_log(f'Токенов использовано всего (вопрос-ответ): {completion.usage.total_tokens}')\n",
        "\n",
        "        # возвращаем ответ\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "# создание экземпляра класса и базы знаний для него\n",
        "employee = Employee()\n",
        "employee.create_search_base(models_info[0][\"fit_doc\"])"
      ],
      "metadata": {
        "id": "eWTXlVJBxq4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Пример использования системы"
      ],
      "metadata": {
        "id": "Yis89lMnFZtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# вспомогательная функция для получения ответа\n",
        "def get_answer(quest):\n",
        "  ans = employee.get_answer(\n",
        "      models_info[0][\"role\"], quest\n",
        "      )\n",
        "  return ans, employee.log\n",
        "\n",
        "# вопросы\n",
        "queries = ['Что делать если ученик не пришел на урок?', 'Как заполнять аналитику после урока?', 'Как получить выплату?']\n",
        "\n",
        "# вывод ответов на вопросы\n",
        "for query in queries:\n",
        "  print('-----------------------------------------')\n",
        "  print(f'Вопрос: {query}')\n",
        "  ans, log = get_answer(query)\n",
        "  print(f'Ответ: {ans}')\n",
        "  print(f'Логи: {log[-1]}')\n",
        "  print('-----------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C86hVwVbA2Dw",
        "outputId": "33847fdd-575a-46a7-8d4a-b0cb2de69646"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------\n",
            "Вопрос: Что делать если ученик не пришел на урок?\n",
            "Ответ: Если ученик не пришел на урок, нужно дождаться 15 минут после начала занятия. Если ученик так и не подключился, тогда нужно заполнить аналитику соответствующим образом (например, Гугл диск --> Папка \"примеры и шаблоны\").\n",
            "Логи: Токенов использовано всего (вопрос-ответ): 2597\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "Вопрос: Как заполнять аналитику после урока?\n",
            "Ответ: После каждого урока необходимо создать новую запись в аналитике посещаемости для каждого наставника. Если студент был присутствует, просто заполняем информацию о посещении урока. Если студента не было, также создаем запись и отмечаем отсутствие. Если возникли форс-мажорные обстоятельства, заполняем аналитику согласно примерам из видео на общем диске.\n",
            "Логи: Токенов использовано всего (вопрос-ответ): 2067\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "Вопрос: Как получить выплату?\n",
            "Ответ: Вы можете получить выплату, обратившись в бот куратора. Если не согласны с суммой выплаты, можно написать в бот куратора при апелляции до 8 числа 17:00.\n",
            "Логи: Токенов использовано всего (вопрос-ответ): 1621\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    }
  ]
}